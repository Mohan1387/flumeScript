#Flume Configuration Starts
# Define a file channel called fileChannel on agent4
agent4.channels.fileChannel1_1.type = file
# on linux FS
agent4.channels.fileChannel1_1.capacity = 100000
agent4.channels.fileChannel1_1.transactionCapacity = 1000
#agent4.channels.fileChannel1_1.maxFileSize = 2146435071
# Define a source for agent4
agent4.sources.source1_1.type = spooldir
# on linux FS

#Spooldir in my case is /home/hadoop/Desktop/flume_sink
agent4.sources.source1_1.spoolDir = /datadump/eventlogs/new
agent4.sources.source1_1.fileHeader = false
agent4.sources.source1_1.fileSuffix = .COMPLETED
agent4.sinks.hdfs-sink1_1.type = hdfs

#Sink is /flume_import under hdfs

agent4.sinks.hdfs-sink1_1.hdfs.path = hdfs://master:54310/user/hdfs/eventlog
agent4.sinks.hdfs-sink1_1.hdfs.batchSize = 100
agent4.sinks.hdfs-sink1_1.hdfs.rollSize = 10000
agent4.sinks.hdfs-sink1_1.hdfs.rollInterval = 0
agent4.sinks.hdfs-sink1_1.hdfs.rollCount = 0
agent4.sinks.hdfs-sink1_1.hdfs.writeFormat=Text
agent4.sinks.hdfs-sink1_1.hdfs.useLocalTimeStamp = true
agent4.sinks.hdfs-sink1_1.hdfs.filePrefix = eventlog-%Y%m%d

agent4.sinks.hdfs-sink1_1.hdfs.fileType = CompressedStream
agent4.sinks.hdfs-sink1_1.hdfs.codeC=snappy
agent4.sources.source1_1.channels = fileChannel1_1
agent4.sinks.hdfs-sink1_1.channel = fileChannel1_1

agent4.sinks =  hdfs-sink1_1
agent4.sources = source1_1
agent4.channels = fileChannel1_1
