# Initialize agent's source, channel and sink
saleagent.sources = TwitterExampleDir
saleagent.channels = memoryChannel
saleagent.sinks = flumeHDFS

# Setting the source to spool directory where the file exists
saleagent.sources.TwitterExampleDir.type = spooldir
saleagent.sources.TwitterExampleDir.spoolDir = /datadump

# Setting the channel to memory
saleagent.channels.memoryChannel.type = memory
# Max number of events stored in the memory channel
saleagent.channels.memoryChannel.capacity = 100000
# saleagent.channels.memoryChannel.batchSize = 15000
saleagent.channels.memoryChannel.transactioncapacity = 1000

# Setting the sink to HDFS
saleagent.sinks.flumeHDFS.type = hdfs
saleagent.sinks.flumeHDFS.hdfs.path = hdfs://master:54310/user/hdfs/eventlog
saleagent.sinks.flumeHDFS.hdfs.fileType = CompressedStream
saleagent.sinks.flumeHDFS.hdfs.codeC=snappy

# Write format can be text or writable
saleagent.sinks.flumeHDFS.hdfs.writeFormat = Text

# use a single csv file at a time
saleagent.sinks.flumeHDFS.hdfs.maxOpenFiles = 1

# rollover file based on maximum size of 10 MB
saleagent.sinks.flumeHDFS.hdfs.rollCount= 10000000
#saleagent.sinks.flumeHDFS.hdfs.rollInterval=0
saleagent.sinks.flumeHDFS.hdfs.rollSize = 0
saleagent.sinks.flumeHDFS.hdfs.batchSize =100

# never rollover based on the number of events
#saleagent.sinks.flumeHDFS.hdfs.rollCount = 0
saleagent.sinks.flumeHDFS.hdfs.filePrefix = %{basename}ArcsiteEventlog
# rollover file based on max time of 1 min
#saleagent.sinks.flumeHDFS.hdfs.rollInterval = 0
# saleagent.sinks.flumeHDFS.hdfs.idleTimeout = 600

# Connect source and sink with channel
saleagent.sources.TwitterExampleDir.channels = memoryChannel
saleagent.sinks.flumeHDFS.channel = memoryChannel
